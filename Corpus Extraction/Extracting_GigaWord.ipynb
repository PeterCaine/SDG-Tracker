{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exploration and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(var_name, open(file_name, r/w/etc))\n",
    "var_name = pickle.load(open(file_name, r/w/etc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T10:02:26.578044Z",
     "start_time": "2020-02-16T10:02:26.437407Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T10:18:22.576988Z",
     "start_time": "2020-02-16T10:18:20.295736Z"
    }
   },
   "outputs": [],
   "source": [
    "with open ('afe199405', 'r') as infile:\n",
    "    soup = BeautifulSoup(infile, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T10:42:31.734854Z",
     "start_time": "2020-02-16T10:42:31.234715Z"
    }
   },
   "outputs": [],
   "source": [
    "#not all elements are news stories with headlines etc.\n",
    "#finds all elements with attribute type = 'story' and creates a list with one document per list item\n",
    "elements = soup.find_all(type = 'story')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T12:38:09.448639Z",
     "start_time": "2020-02-16T12:38:09.438887Z"
    }
   },
   "outputs": [],
   "source": [
    "def dict_builder(soup_object):\n",
    "\n",
    "    news_dict={}\n",
    "\n",
    "    elements = soup.find_all(type = 'story')\n",
    "\n",
    "    for document in elements:\n",
    "        #we'll use the document identifier for index in datafram\n",
    "        index = document['id']\n",
    "        #the date may be useful in future, not all stories have dates\n",
    "        if document.dateline:\n",
    "            clean_date = document.dateline.text.strip()\n",
    "        else:\n",
    "            clean_date = 'None'\n",
    "        #the headline will be part of the vector (not all stories have headlines)    \n",
    "        if document.headline:\n",
    "            clean_headline = document.headline.text.strip()\n",
    "        else:\n",
    "            clean_headline = 'None'\n",
    "        # the first five sentences will be the other part of the vector - the limit=5 argument only returns 5\n",
    "        #all linebreaks are replaced with spaces\n",
    "        first_five = [el.text.strip().replace('\\n', ' ') for el in document.find_all('p', limit=5)]\n",
    "        #the dict is populated with the id as key and a tuple of date, headline and first five sentences\n",
    "        news_dict[index]=(clean_date, clean_headline, first_five) \n",
    "\n",
    "    return news_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T11:22:23.842948Z",
     "start_time": "2020-02-16T11:22:23.827324Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#inspect dictionary output here\n",
    "# news_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T11:32:29.106356Z",
     "start_time": "2020-02-16T11:32:29.075117Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>first_five</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>AFE19940512.0003</td>\n",
       "      <td>UNDATED, May 12 (AFP)</td>\n",
       "      <td>Tributes pour in for late British Labour Party...</td>\n",
       "      <td>[Tributes poured in from around the world Thur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AFE19940512.0004</td>\n",
       "      <td>WASHINGTON, May 12 (AFP)</td>\n",
       "      <td>France rules out participation in military inv...</td>\n",
       "      <td>[France would not join a US military invasion ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AFE19940512.0005</td>\n",
       "      <td>WASHINGTON, May 12 (AFP)</td>\n",
       "      <td>Chinese dissidents in US favor partial revokin...</td>\n",
       "      <td>[Chinese dissidents in the United States gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AFE19940512.0006</td>\n",
       "      <td>YEREVAN, May 12 (AFP)</td>\n",
       "      <td>Nagorno Karabakh hit by further clashes amid c...</td>\n",
       "      <td>[The Azerbaijani enclave of Nagorno Karabakh w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AFE19940512.0008</td>\n",
       "      <td>INDIANAPOLIS, Indiana, May 12 (AFP)</td>\n",
       "      <td>This restart looks good by Jim Slater</td>\n",
       "      <td>[This time, Nigel Mansell will not be left beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AFE19940531.0385</td>\n",
       "      <td>UNITED NATIONS, May 31 (AFP)</td>\n",
       "      <td>Security Council agrees on draft resolution ur...</td>\n",
       "      <td>[The Security Council agreed late Tuesday on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AFE19940531.0386</td>\n",
       "      <td>SANAA, June 1 (AFP)</td>\n",
       "      <td>War-torn Yemen hit by acute shortages by Laure...</td>\n",
       "      <td>[The conflict in Yemen has created an acute sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AFE19940531.0387</td>\n",
       "      <td>VIENNA, June 1 (AFP)</td>\n",
       "      <td>North Korea ready to set aside 40 fuel rods fo...</td>\n",
       "      <td>[North Korea is prepared to store 40 fuel rods...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AFE19940531.0389</td>\n",
       "      <td>CAEN, France, June 1 (AFP)</td>\n",
       "      <td>Authorities mount enormous security, logistics...</td>\n",
       "      <td>[French authorities are mounting an enormous l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AFE19940531.0390</td>\n",
       "      <td>TOKYO, June 1 (AFP)</td>\n",
       "      <td>Japan confirms North Korea's missile launch</td>\n",
       "      <td>[Japan confirmed Wednesday that North Korea fi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5933 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 date  \\\n",
       "AFE19940512.0003                UNDATED, May 12 (AFP)   \n",
       "AFE19940512.0004             WASHINGTON, May 12 (AFP)   \n",
       "AFE19940512.0005             WASHINGTON, May 12 (AFP)   \n",
       "AFE19940512.0006                YEREVAN, May 12 (AFP)   \n",
       "AFE19940512.0008  INDIANAPOLIS, Indiana, May 12 (AFP)   \n",
       "...                                               ...   \n",
       "AFE19940531.0385         UNITED NATIONS, May 31 (AFP)   \n",
       "AFE19940531.0386                  SANAA, June 1 (AFP)   \n",
       "AFE19940531.0387                 VIENNA, June 1 (AFP)   \n",
       "AFE19940531.0389           CAEN, France, June 1 (AFP)   \n",
       "AFE19940531.0390                  TOKYO, June 1 (AFP)   \n",
       "\n",
       "                                                           headline  \\\n",
       "AFE19940512.0003  Tributes pour in for late British Labour Party...   \n",
       "AFE19940512.0004  France rules out participation in military inv...   \n",
       "AFE19940512.0005  Chinese dissidents in US favor partial revokin...   \n",
       "AFE19940512.0006  Nagorno Karabakh hit by further clashes amid c...   \n",
       "AFE19940512.0008              This restart looks good by Jim Slater   \n",
       "...                                                             ...   \n",
       "AFE19940531.0385  Security Council agrees on draft resolution ur...   \n",
       "AFE19940531.0386  War-torn Yemen hit by acute shortages by Laure...   \n",
       "AFE19940531.0387  North Korea ready to set aside 40 fuel rods fo...   \n",
       "AFE19940531.0389  Authorities mount enormous security, logistics...   \n",
       "AFE19940531.0390        Japan confirms North Korea's missile launch   \n",
       "\n",
       "                                                         first_five  \n",
       "AFE19940512.0003  [Tributes poured in from around the world Thur...  \n",
       "AFE19940512.0004  [France would not join a US military invasion ...  \n",
       "AFE19940512.0005  [Chinese dissidents in the United States gener...  \n",
       "AFE19940512.0006  [The Azerbaijani enclave of Nagorno Karabakh w...  \n",
       "AFE19940512.0008  [This time, Nigel Mansell will not be left beh...  \n",
       "...                                                             ...  \n",
       "AFE19940531.0385  [The Security Council agreed late Tuesday on t...  \n",
       "AFE19940531.0386  [The conflict in Yemen has created an acute sh...  \n",
       "AFE19940531.0387  [North Korea is prepared to store 40 fuel rods...  \n",
       "AFE19940531.0389  [French authorities are mounting an enormous l...  \n",
       "AFE19940531.0390  [Japan confirmed Wednesday that North Korea fi...  \n",
       "\n",
       "[5933 rows x 3 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe construction - orient = index means that the key of the dict is the index of the df\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "columns=['date', 'headline', 'first_five']\n",
    "df = pd.DataFrame.from_dict(news_dict, orient= 'index', columns = columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# working function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T08:53:57.500429Z",
     "start_time": "2020-02-18T08:53:57.469176Z"
    }
   },
   "outputs": [],
   "source": [
    "def dict_builder(soup_object):\n",
    "\n",
    "    news_dict={}\n",
    "\n",
    "    elements = soup.find_all(type = 'story')\n",
    "\n",
    "    for document in elements:\n",
    "        #we'll use the document identifier for index in datafram\n",
    "        index = document['id']\n",
    "        #the date may be useful in future, not all stories have dates\n",
    "        if document.dateline:\n",
    "            clean_date = document.dateline.text.strip()\n",
    "        else:\n",
    "            clean_date = 'None'\n",
    "        #the headline will be part of the vector (not all stories have headlines)    \n",
    "        if document.headline:\n",
    "            clean_headline = document.headline.text.strip()\n",
    "        else:\n",
    "            clean_headline = 'None'\n",
    "        # the first five sentences will be the other part of the vector - the limit=5 argument only returns 5\n",
    "        #all linebreaks are replaced with spaces\n",
    "        first_five = [el.text.strip().replace('\\n', ' ') for el in document.find_all('p', limit=5)]\n",
    "        #the dict is populated with the id as key and a tuple of date, headline and first five sentences\n",
    "        news_dict[index]=(clean_date, clean_headline, first_five) \n",
    "\n",
    "    return news_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En masse\n",
    "\n",
    "- cycle through one large dataset (afp_eng; gzipped files)\n",
    "\n",
    "- extract: name, date, headline, first five sentences as dictionary\n",
    "\n",
    "- pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T08:53:58.531756Z",
     "start_time": "2020-02-18T08:53:58.422386Z"
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T09:02:09.434873Z",
     "start_time": "2020-02-18T08:54:09.392527Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afp_eng_200609.gz\n",
      "afp_eng_200610.gz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-17de3d7d0bc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mbasename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mlist_o_dicts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_builder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_builder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34mf'./pickles/{basename}.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    308\u001b[0m          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains_replacement_characters\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m              self.builder.prepare_markup(\n\u001b[1;32m--> 310\u001b[1;33m                  markup, from_encoding, exclude_encodings=exclude_encodings)):\n\u001b[0m\u001b[0;32m    311\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\bs4\\builder\\_lxml.py\u001b[0m in \u001b[0;36mprepare_markup\u001b[1;34m(self, markup, user_specified_encoding, exclude_encodings, document_declared_encoding)\u001b[0m\n\u001b[0;32m    154\u001b[0m         detector = EncodingDetector(\n\u001b[0;32m    155\u001b[0m             markup, try_encodings, is_html, exclude_encodings)\n\u001b[1;32m--> 156\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencodings\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocument_declared_encoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\bs4\\dammit.py\u001b[0m in \u001b[0;36mencodings\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[1;31m# encoding.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchardet_encoding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchardet_encoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchardet_dammit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_usable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchardet_encoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtried\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchardet_encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\bs4\\dammit.py\u001b[0m in \u001b[0;36mchardet_dammit\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mchardet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[1;31m#import chardet.constants\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m#chardet.constants._debug = 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\chardet\\__init__.py\u001b[0m in \u001b[0;36mdetect\u001b[1;34m(byte_str)\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mbyte_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUniversalDetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\chardet\\universaldetector.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, byte_str)\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_charset_probers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLatin1Prober\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mprober\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_charset_probers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mprober\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mProbingState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFOUND_IT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m                     self.result = {'encoding': prober.charset_name,\n\u001b[0;32m    213\u001b[0m                                    \u001b[1;34m'confidence'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprober\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_confidence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\chardet\\latin1prober.py\u001b[0m in \u001b[0;36mfeed\u001b[1;34m(self, byte_str)\u001b[0m\n\u001b[0;32m    124\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_freq_counter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_last_char_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchar_class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list_o_dicts = []\n",
    "for file in glob.glob('GIGAword/giga.tar/gigaword/gigaword_eng_5_d1/data/afp_eng/*'):\n",
    "\n",
    "    with gzip.open(file, 'r') as infile:\n",
    "        basename = os.path.basename(file)\n",
    "        soup = BeautifulSoup(infile, 'lxml')\n",
    "        list_o_dicts.append(dict_builder(soup))\n",
    "        pickle.dump(dict_builder(soup), open( f'./pickles/{basename}.pkl', \"wb\" ))\n",
    "        print(basename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract pickles to large dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T07:53:17.441296Z",
     "start_time": "2020-02-18T07:52:53.044751Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "df_list=[]\n",
    "\n",
    "for file in glob.glob('pickles/*'):\n",
    "    pickle_dict = pickle.load(open(file, 'rb'))\n",
    "    columns=['date', 'headline', 'first_five']\n",
    "    df_list.append(pd.DataFrame.from_dict(pickle_dict, orient='index', columns = columns))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T07:53:28.826113Z",
     "start_time": "2020-02-18T07:53:28.681218Z"
    }
   },
   "outputs": [],
   "source": [
    "big_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>first_five</th>\n",
       "      <th>related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AFP_ENG_19940512.0003</th>\n",
       "      <td>UNDATED, May 12 (AFP)</td>\n",
       "      <td>Tributes pour in for late British Labour Party...</td>\n",
       "      <td>[Tributes poured in from around the world Thur...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFP_ENG_19940512.0004</th>\n",
       "      <td>WASHINGTON, May 12 (AFP)</td>\n",
       "      <td>France rules out participation in military inv...</td>\n",
       "      <td>[France would not join a US military invasion ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFP_ENG_19940512.0005</th>\n",
       "      <td>WASHINGTON, May 12 (AFP)</td>\n",
       "      <td>Chinese dissidents in US favor partial revokin...</td>\n",
       "      <td>[Chinese dissidents in the United States gener...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFP_ENG_19940512.0006</th>\n",
       "      <td>YEREVAN, May 12 (AFP)</td>\n",
       "      <td>Nagorno Karabakh hit by further clashes amid c...</td>\n",
       "      <td>[The Azerbaijani enclave of Nagorno Karabakh w...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFP_ENG_19940512.0008</th>\n",
       "      <td>INDIANAPOLIS, Indiana, May 12 (AFP)</td>\n",
       "      <td>This restart looks good by Jim Slater</td>\n",
       "      <td>[This time, Nigel Mansell will not be left beh...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFP_ENG_20061031.0735</th>\n",
       "      <td>BEIJING, Nov 1, 2006</td>\n",
       "      <td>Secret talks, discreet brokering ends NKorea d...</td>\n",
       "      <td>[One year of diplomatic deadlock on  the North...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFP_ENG_20061031.0736</th>\n",
       "      <td>JAKARTA, Nov 1, 2006</td>\n",
       "      <td>Indonesia nabs couriers for top terrorist fugi...</td>\n",
       "      <td>[Indonesia's anti-terrorist police  arrested t...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFP_ENG_20061031.0737</th>\n",
       "      <td>HONG KONG, Nov 1, 2006</td>\n",
       "      <td>Hong Kong shares end morning higher on fund in...</td>\n",
       "      <td>[Hong Kong share prices finished  the morning ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFP_ENG_20061031.0738</th>\n",
       "      <td>KUALA LUMPUR, Nov 1, 2006</td>\n",
       "      <td>Piracy on decline, but Bangladesh a hotspot: IMB</td>\n",
       "      <td>[Piracy declined globally this  year, but Chit...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFP_ENG_20061031.0739</th>\n",
       "      <td>TOKYO, Nov 1, 2006</td>\n",
       "      <td>Japan's Mizuho Financial to list on NYSE</td>\n",
       "      <td>[Mizuho Financial Group, Japan's  second-large...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1409987 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      date  \\\n",
       "AFP_ENG_19940512.0003                UNDATED, May 12 (AFP)   \n",
       "AFP_ENG_19940512.0004             WASHINGTON, May 12 (AFP)   \n",
       "AFP_ENG_19940512.0005             WASHINGTON, May 12 (AFP)   \n",
       "AFP_ENG_19940512.0006                YEREVAN, May 12 (AFP)   \n",
       "AFP_ENG_19940512.0008  INDIANAPOLIS, Indiana, May 12 (AFP)   \n",
       "...                                                    ...   \n",
       "AFP_ENG_20061031.0735                 BEIJING, Nov 1, 2006   \n",
       "AFP_ENG_20061031.0736                 JAKARTA, Nov 1, 2006   \n",
       "AFP_ENG_20061031.0737               HONG KONG, Nov 1, 2006   \n",
       "AFP_ENG_20061031.0738            KUALA LUMPUR, Nov 1, 2006   \n",
       "AFP_ENG_20061031.0739                   TOKYO, Nov 1, 2006   \n",
       "\n",
       "                                                                headline  \\\n",
       "AFP_ENG_19940512.0003  Tributes pour in for late British Labour Party...   \n",
       "AFP_ENG_19940512.0004  France rules out participation in military inv...   \n",
       "AFP_ENG_19940512.0005  Chinese dissidents in US favor partial revokin...   \n",
       "AFP_ENG_19940512.0006  Nagorno Karabakh hit by further clashes amid c...   \n",
       "AFP_ENG_19940512.0008              This restart looks good by Jim Slater   \n",
       "...                                                                  ...   \n",
       "AFP_ENG_20061031.0735  Secret talks, discreet brokering ends NKorea d...   \n",
       "AFP_ENG_20061031.0736  Indonesia nabs couriers for top terrorist fugi...   \n",
       "AFP_ENG_20061031.0737  Hong Kong shares end morning higher on fund in...   \n",
       "AFP_ENG_20061031.0738   Piracy on decline, but Bangladesh a hotspot: IMB   \n",
       "AFP_ENG_20061031.0739           Japan's Mizuho Financial to list on NYSE   \n",
       "\n",
       "                                                              first_five  \\\n",
       "AFP_ENG_19940512.0003  [Tributes poured in from around the world Thur...   \n",
       "AFP_ENG_19940512.0004  [France would not join a US military invasion ...   \n",
       "AFP_ENG_19940512.0005  [Chinese dissidents in the United States gener...   \n",
       "AFP_ENG_19940512.0006  [The Azerbaijani enclave of Nagorno Karabakh w...   \n",
       "AFP_ENG_19940512.0008  [This time, Nigel Mansell will not be left beh...   \n",
       "...                                                                  ...   \n",
       "AFP_ENG_20061031.0735  [One year of diplomatic deadlock on  the North...   \n",
       "AFP_ENG_20061031.0736  [Indonesia's anti-terrorist police  arrested t...   \n",
       "AFP_ENG_20061031.0737  [Hong Kong share prices finished  the morning ...   \n",
       "AFP_ENG_20061031.0738  [Piracy declined globally this  year, but Chit...   \n",
       "AFP_ENG_20061031.0739  [Mizuho Financial Group, Japan's  second-large...   \n",
       "\n",
       "                       related  \n",
       "AFP_ENG_19940512.0003      NaN  \n",
       "AFP_ENG_19940512.0004      NaN  \n",
       "AFP_ENG_19940512.0005      NaN  \n",
       "AFP_ENG_19940512.0006      NaN  \n",
       "AFP_ENG_19940512.0008      NaN  \n",
       "...                        ...  \n",
       "AFP_ENG_20061031.0735      NaN  \n",
       "AFP_ENG_20061031.0736      NaN  \n",
       "AFP_ENG_20061031.0737      NaN  \n",
       "AFP_ENG_20061031.0738      NaN  \n",
       "AFP_ENG_20061031.0739      NaN  \n",
       "\n",
       "[1409987 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.set_options('display.max_rows', None)\n",
    "\n",
    "big_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test - keyword search - update 'related' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T08:05:41.511575Z",
     "start_time": "2020-02-18T08:05:41.504572Z"
    }
   },
   "outputs": [],
   "source": [
    "big_df['related'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T08:14:39.759590Z",
     "start_time": "2020-02-18T08:14:39.177901Z"
    }
   },
   "outputs": [],
   "source": [
    "# .loc is necessary otherwise error reads \"'Series' objects are mutable, thus they cannot be hashed\"\n",
    "big_df.loc[big_df['first_five'].str.contains('combat') & big_df['headline'].str.contains('poverty'), 'related'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>first_five</th>\n",
       "      <th>related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AFP_ENG_19940512.0003</th>\n",
       "      <td>UNDATED, May 12 (AFP)</td>\n",
       "      <td>Tributes pour in for late British Labour Party...</td>\n",
       "      <td>[Tributes poured in from around the world Thur...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        date  \\\n",
       "AFP_ENG_19940512.0003  UNDATED, May 12 (AFP)   \n",
       "\n",
       "                                                                headline  \\\n",
       "AFP_ENG_19940512.0003  Tributes pour in for late British Labour Party...   \n",
       "\n",
       "                                                              first_five  \\\n",
       "AFP_ENG_19940512.0003  [Tributes poured in from around the world Thur...   \n",
       "\n",
       "                       related  \n",
       "AFP_ENG_19940512.0003      1.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df[big_df['related']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-18T08:44:15.820328Z",
     "start_time": "2020-02-18T08:28:49.437Z"
    }
   },
   "outputs": [],
   "source": [
    "big_df.loc[big_df['headline'].str.contains('Tributes') & big_df['headline'].str.contains('Labour'), 'related'] = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
